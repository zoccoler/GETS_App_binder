{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções de tratamento da lista de equipamentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_equip_data(file_path_list):\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    lista_eqp_list = []\n",
    "    for file_path in file_path_list:\n",
    "        lista_eqp = pd.read_excel(file_path,skiprows=3,header=2,dtype={'Patrimônio': str, 'Tipo Equipamento': str})\n",
    "        lista_eqp = lista_eqp.drop(['Localização','Modelo','Fornecedor','Núm. Doc. da Aquisição','Nota Fiscal','Garantia',\n",
    "                                'Parecer Desativação','Contrato','Vida Útil','Equipamento Crítico',\n",
    "                                   'Descrição Complementar'], axis=1)\n",
    "        lista_eqp['Aquisição'] = pd.to_datetime(lista_eqp['Aquisição'],dayfirst=True)\n",
    "        lista_eqp['Data Desativação'] = pd.to_datetime(lista_eqp['Data Desativação'],dayfirst=True)\n",
    "        lista_eqp.sort_values(by=['Aquisição'], inplace=True)\n",
    "        lista_eqp_list.append(lista_eqp)\n",
    "    lista_eqp = pd.concat(lista_eqp_list,ignore_index=True)\n",
    "    lista_eqp.drop_duplicates(inplace=True)\n",
    "    return(lista_eqp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_equip_data(lista_eqp):\n",
    "    import pandas as pd\n",
    "    # Delete invalid dates ( =-1, which is equivalent to dates before 1900)\n",
    "    lista_eqp = lista_eqp.drop(lista_eqp[lista_eqp['Aquisição'] < pd.to_datetime(1900, format='%Y')].index)\n",
    "    \n",
    "    # Delete equipments with 'DESATIVADO=SIM' AND without disable date\n",
    "    lista_eqp = lista_eqp.drop(lista_eqp[(lista_eqp['Desativado']=='SIM') & (pd.isna(lista_eqp['Data Desativação']))].index)\n",
    "    \n",
    "    # Delete equipments tagged with 'DESATIVADO=NÃO' AND without disable date AND also tagged with 'BAIXADO=SIM'\n",
    "    lista_eqp = lista_eqp.drop(lista_eqp[(lista_eqp['Desativado']=='NÃO') & (pd.isna(lista_eqp['Data Desativação'])) & ((lista_eqp['Baixado']=='SIM'))].index)\n",
    "    \n",
    "    \n",
    "    # Consider active (i.e., remove disable date) equipments tagged with 'DESATIVADO=NÃO' AND 'BAIXADO=NÃO', even if they have disable date \n",
    "    # Flags for filtering\n",
    "    is_not_disabled = lista_eqp['Desativado']=='NÃO'\n",
    "    is_not_down = lista_eqp['Baixado']=='NÃO'\n",
    "    has_disable_date = pd.notna(lista_eqp['Data Desativação']) \n",
    "    lista_eqp.loc[lista_eqp[is_not_disabled & has_disable_date & is_not_down].index , ['Data Desativação']] = pd.NaT\n",
    "    \n",
    "    #Consider active equipments tagged with 'DESATIVADO=SIM', AND that have an disable date, \n",
    "    #     AND tagged with 'PERMITIR O.S.=SIM', AND tagged with 'BAIXADO=NÃO'\n",
    "    # Flags for filtering\n",
    "    is_disabled = lista_eqp['Desativado']=='SIM'\n",
    "    has_disable_date = pd.notna(lista_eqp['Data Desativação'])\n",
    "    allow_OS = lista_eqp['Permitir O.S.']=='SIM'\n",
    "    is_not_down = lista_eqp['Baixado']=='NÃO'\n",
    "    lista_eqp.loc[lista_eqp[(is_disabled & has_disable_date & allow_OS & is_not_down)].index,['Data Desativação']] = pd.NaT\n",
    "    \n",
    "    return(lista_eqp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrange_equip_data(lista_eqp):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    # Copy dataframe\n",
    "    lista_eqp2 = lista_eqp.copy()\n",
    "    # On original dataframe, create column 'Ativo' (with Trues) and renames column 'Aquisição' as 'Data'\n",
    "    lista_eqp.loc[:,'Ativo'] = np.ones(len(lista_eqp),dtype=bool)\n",
    "    lista_eqp.rename(columns={'Aquisição':'Data'}, inplace=True)\n",
    "    # On dataframe copy, remove active equipments and creates column 'Ativo' (with Falses)\n",
    "    # also removes column 'Aquisição' and renames column 'Data Desativação' as 'Data'\n",
    "    lista_eqp2 = lista_eqp2[pd.notna(lista_eqp2['Data Desativação'])]\n",
    "    lista_eqp2.loc[:,'Ativo'] = np.zeros(len(lista_eqp2),dtype=bool)\n",
    "    lista_eqp2 = lista_eqp2.drop(['Aquisição'], axis=1)\n",
    "    lista_eqp2.rename(columns={'Data Desativação':'Data'}, inplace=True)\n",
    "    # Concatenates original and copy\n",
    "    double_lista_eqp = pd.concat([lista_eqp,lista_eqp2],sort=True)\n",
    "    # Redesign indexes as double indexes 'Data' and 'Patrimônio'\n",
    "    double_lista_eqp = double_lista_eqp.set_index(['Data','Patrimônio'])\n",
    "    double_lista_eqp = double_lista_eqp.sort_index()\n",
    "    # Remove duplicates\n",
    "    double_lista_eqp = double_lista_eqp[~double_lista_eqp.index.duplicated()]\n",
    "    \n",
    "    return(double_lista_eqp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_equips_data(file_path_list):\n",
    "    df = load_equip_data(file_path_list)\n",
    "    df = clean_equip_data(df)\n",
    "    df = arrange_equip_data(df)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_equip_amount(df,equip,start_date=0, end_date=10):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    selected_equip = df['Tipo Equipamento']==equip[0]\n",
    "    for eq in equip:\n",
    "        selected_equip = (selected_equip) | (df['Tipo Equipamento']==eq)\n",
    "    acquired = df['Ativo']==True\n",
    "    deactivated = df['Ativo']==False\n",
    "    \n",
    "    equip_acquired_cumsum = (selected_equip & acquired).cumsum()\n",
    "    equip_deactivated_cumsum = (selected_equip & deactivated).cumsum()\n",
    "    \n",
    "    equip_amount = equip_acquired_cumsum - equip_deactivated_cumsum\n",
    "    equip_amount_data = df[selected_equip].copy()\n",
    "    equip_amount_data.loc[:,'Quantidade de Equipamentos'] = equip_amount\n",
    "    # Sort dates in accending order\n",
    "    equip_amount_data.sort_index(level=0,inplace=True)\n",
    "    return(equip_amount_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções de tratamento das OS Encerradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_OS_data(closed_OS_path_list):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    whole_data = []\n",
    "    for file_path in closed_OS_path_list:\n",
    "        closed_OS = pd.read_excel(file_path,skiprows=3,header=2,dtype={'Núm. O.S.': str, 'Tipo Equip.':str, 'Patrimônio': str, 'Tempo SOS-OSP (horas)':np.float64})\n",
    "        closed_OS = closed_OS.drop(['Grupo','Programa MP','Modelo','Duração (dias)','Equipamento Crítico',\n",
    "                               'Tempo SOS-OSP (dias)','Indisponibilidade (dias)'], axis=1)\n",
    "        closed_OS['Abertura'] = pd.to_datetime(closed_OS['Abertura'],dayfirst=True)\n",
    "        closed_OS['Encerramento'] = pd.to_datetime(closed_OS['Encerramento'],dayfirst=True)\n",
    "        closed_OS.sort_values(by=['Abertura'], inplace=True)\n",
    "        closed_OS.loc[closed_OS['Tempo SOS-OSP (horas)']==0, 'Tempo SOS-OSP (horas)'] = 1/60\n",
    "        whole_data.append(closed_OS)\n",
    "    whole_data = pd.concat(whole_data,ignore_index=True)\n",
    "    whole_data.drop_duplicates(inplace=True)\n",
    "\n",
    "    return(whole_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função de tratamento de OS Pendente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_open_OS_data(df,open_OS_path):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import os\n",
    "\n",
    "    open_OS = pd.read_excel(open_OS_path,skiprows=3,header=2,dtype={'Num.': str, 'Patrimônio': str, 'Estado':str, 'Classe':str})\n",
    "    open_OS = open_OS.drop(['Núm.Orgão','N. Série','Grupo','Marca','Modelo','No Nec','Equipamento Crítico'], axis=1)\n",
    "    # Put dates in the right format\n",
    "    open_OS['Abertura'] = pd.to_datetime(open_OS['Abertura'],dayfirst=True)\n",
    "    open_OS['Dt. Última Transição'] = pd.to_datetime(open_OS['Dt. Última Transição'],dayfirst=True)\n",
    "    open_OS.sort_values('Abertura', inplace=True)\n",
    "    \n",
    "    # Find OS that are ready to treat separatedly\n",
    "    OS_ready = open_OS['Estado']=='OSP - OS Pronta'\n",
    "    open_OS = open_OS.drop(['Estado'], axis=1)\n",
    "    # Create column 'Processada' (with Falses) (at first treat all OS as unfinished)\n",
    "    open_OS.loc[:,'Processada'] = np.zeros(len(open_OS),dtype=bool)\n",
    "    # Create a copy with just the OS that are ready\n",
    "    open_OS_ready = open_OS.loc[OS_ready].copy()\n",
    "    # Change status of column 'Processada' to True in this copy and redefines 'Abertura' as 'Dt. Última Transição'\n",
    "    open_OS_ready.loc[:,'Processada'] = True\n",
    "    open_OS_ready.loc[:,'Abertura'] = open_OS_ready.loc[:,'Dt. Última Transição']\n",
    "    #################################\n",
    "    #### Now, in both dataframes ####\n",
    "    # Insert new column 'Encerramento' (empty), but attribute 'Dt. Última Transição' to OS that are ready\n",
    "    open_OS.insert(4,'Encerramento','')\n",
    "    open_OS.loc[OS_ready,'Encerramento'] = open_OS.loc[OS_ready,'Dt. Última Transição']\n",
    "    open_OS_ready.insert(4,'Encerramento','')\n",
    "    open_OS_ready.loc[:,'Encerramento'] = open_OS_ready.loc[:,'Dt. Última Transição']\n",
    "    # Insert new column 'Classe' (with 'Manutenção Corretiva'). Obs: tha excel table was generated with the \n",
    "    #    filter 'Manutenção Corretiva', so all OS's should be of this class\n",
    "#     open_OS.insert(1,'Classe','Manutenção Corretiva')\n",
    "#     open_OS_ready.insert(1,'Classe','Manutenção Corretiva')\n",
    "    # Find 'Classe' MC and replace by 'Manutenção Corretiva' (same name as in OS ready file)\n",
    "    open_OS_MC = open_OS['Classe'] == 'MC'\n",
    "    open_OS_ready_MC = open_OS_ready['Classe'] == 'MC'\n",
    "    open_OS.loc[open_OS_MC, 'Classe'] = \"Manutenção Corretiva\"\n",
    "    open_OS_ready.loc[open_OS_ready_MC, 'Classe'] = \"Manutenção Corretiva\"\n",
    "    \n",
    "    # delete the column 'Dt. Última Transição' (not necessary anymore) and renames some column to match those of the \n",
    "    #    closed_OS dataframe\n",
    "    open_OS = open_OS.drop(['Dt. Última Transição'], axis=1)\n",
    "    open_OS_ready = open_OS_ready.drop(['Dt. Última Transição'], axis=1)\n",
    "    open_OS.rename(columns={\"Num.\": \"Núm. O.S.\", \"Abertura\": \"Abertura\"},inplace=True)\n",
    "    open_OS_ready.rename(columns={\"Num.\": \"Núm. O.S.\", \"Abertura\": \"Abertura\"},inplace=True)\n",
    "    ################################\n",
    "    # Concatenate closed_OS dataframe with open_OS and open_OS_ready dataframes\n",
    "    df = pd.concat([df,open_OS,open_OS_ready],ignore_index=True)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organiza dados de OS (junta pendente com fechada e trata dados de duração de OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrange_OS_data(whole_data,open_OS_path_list):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    # Copy dataframe\n",
    "    whole_data2 = whole_data.copy()\n",
    "    whole_data3 = whole_data.copy()\n",
    "    # On original dataframe, create column 'Processada' (with Falses)\n",
    "    whole_data.loc[:,'Processada'] = np.zeros(len(whole_data),dtype=bool)\n",
    "    # load open_OS data and concatenate it with original dataframe (whole_data, which contains closed OS's)\n",
    "    whole_data = load_open_OS_data(whole_data,open_OS_path_list[0])\n",
    "    # On copy, changes date 'Abertura' to the moment when the OS was processed\n",
    "    whole_data2['Abertura'] = whole_data2['Abertura'] + pd.to_timedelta(whole_data2['Tempo SOS-OSP (horas)'], unit='h')\n",
    "    # On copy, create column 'Processada' (with Trues)\n",
    "    whole_data2.loc[:,'Processada'] = np.ones(len(whole_data2),dtype=bool)\n",
    "    # Concatenate data\n",
    "    double_whole_data = pd.concat([whole_data,whole_data2])\n",
    "    # Renames column 'Abertura' as 'Data'\n",
    "    double_whole_data.rename(columns={'Abertura':'Data'}, inplace=True)\n",
    "    # Redesign indexes as double indexes 'Data' and 'Núm. O.S.'\n",
    "    double_whole_data = double_whole_data.set_index(['Data','Núm. O.S.'])\n",
    "    # Sort dates in accending order\n",
    "    double_whole_data = double_whole_data.sort_index()\n",
    "    # Remove duplicates (I downloaded the same day twice somewhere)\n",
    "    double_whole_data = double_whole_data[~double_whole_data.index.duplicated()]\n",
    "    \n",
    "    ## Arrange data for OS duration ##\n",
    "    # Change 'Abertura' date to OS processed date\n",
    "    whole_data3['Abertura'] = whole_data3['Abertura'] + pd.to_timedelta(whole_data3['Tempo SOS-OSP (horas)'], unit='h')\n",
    "    # Rename 'Abertura' (which is now processed date) to 'Data'\n",
    "    whole_data3.rename(columns={'Abertura':'Data'}, inplace=True)\n",
    "    # Drop 'Encerramento' (not used for OS duration because we use duration from openning to processed)\n",
    "    whole_data3 = whole_data3.drop(['Encerramento'],axis=1)\n",
    "    # Set index to 'Data' and 'Núm O.S.'\n",
    "    whole_data3 = whole_data3.set_index(['Data','Núm. O.S.'])\n",
    "    # Sort index by date (when equal dates, sort by 'Núm OS' string)\n",
    "    whole_data3 = whole_data3.sort_index()\n",
    "    # Drop duplicated items (same date and same 'Núm O.S.')\n",
    "    whole_data3 = whole_data3[~whole_data3.index.duplicated()]\n",
    "    # Remove 'Núm O.S.' from index (leave just the dates as index now)\n",
    "    whole_data3 = whole_data3.reset_index(level=['Núm. O.S.'])\n",
    "    \n",
    "    return(double_whole_data, whole_data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_OS_data(closed_OS_path_list,open_OS_path_list):\n",
    "    df = load_OS_data(closed_OS_path_list)\n",
    "    df, df2 = arrange_OS_data(df,open_OS_path_list)\n",
    "    return(df, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_equip_break_rate(df,equip,start_date=0, end_date=10):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    selected_equip = df['Tipo Equip.']==equip[0]\n",
    "    for eq in equip:\n",
    "        selected_equip = (selected_equip) | (df['Tipo Equip.']==eq)\n",
    "\n",
    "    maintenance_type = 'Manutenção Corretiva'\n",
    "    selected_maintenance = df['Classe']==maintenance_type\n",
    "    opened = df['Processada']==False\n",
    "    closed = df['Processada']==True\n",
    "\n",
    "    OS_opened_cumsum = (selected_equip & selected_maintenance & opened).cumsum()\n",
    "    OS_processed_cumsum = (selected_equip & selected_maintenance & closed).cumsum()\n",
    "\n",
    "    break_rate = OS_opened_cumsum - OS_processed_cumsum\n",
    "    break_rate_data = df[selected_equip & selected_maintenance].copy()\n",
    "    if break_rate_data.empty==False:\n",
    "        break_rate_data['Taxa de Quebra'] = break_rate\n",
    "    return(break_rate_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_equip_OS_duration(equip,df):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    selected_equip = df['Tipo Equip.']==equip[0]\n",
    "    for eq in equip:\n",
    "        selected_equip = (selected_equip) | (df['Tipo Equip.']==eq)\n",
    "\n",
    "    maintenance_type = 'Manutenção Corretiva'\n",
    "    selected_maintenance = df['Classe']==maintenance_type\n",
    "    \n",
    "    duration_data = df[selected_equip & selected_maintenance]\n",
    "    return(duration_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função de aquisição de equipamentos totais e disponíveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_available_equip(selected_equip,equips_data,OS_data):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    # get selected equipment amount (over time)\n",
    "    equip_amount_data = get_equip_amount(equips_data,selected_equip)\n",
    "    \n",
    "    # get selected equipment break rate (over time)\n",
    "    break_data = get_equip_break_rate(OS_data,selected_equip)\n",
    "        \n",
    "    # Replaces content of columns 'Ativo' and 'Processada' by 1 (when equipment is acquired or fixed) or -1 (when equipment\n",
    "    #       is disabled or broken)\n",
    "    dates1 = equip_amount_data.index.get_level_values(0)\n",
    "    amounts = equip_amount_data['Ativo'].astype(int)\n",
    "    amounts[amounts==0] = -1\n",
    "    \n",
    "    if break_data.empty:\n",
    "        available_equips = pd.concat([amounts])\n",
    "        available_equips.rename(0, inplace=True)\n",
    "    else:\n",
    "        dates2 = break_data.index.get_level_values(0)\n",
    "        breaks = break_data['Processada'].astype(int)\n",
    "        breaks[breaks==0] = -1\n",
    "        #concatenate data\n",
    "        available_equips = pd.concat([amounts,breaks])\n",
    "    #removes second index and sort by date\n",
    "    available_equips = available_equips.reset_index(level=[1])\n",
    "    available_equips = available_equips.drop(['Patrimônio'],axis=1)\n",
    "    available_equips.sort_index(inplace=True)\n",
    "    # Adds a new column 'Quantidade Disponível' with the cumulative sum\n",
    "    available_equips.loc[:,'Quantidade Disponível'] = available_equips.cumsum()[0]\n",
    "    return(available_equips,equip_amount_data,break_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrange_equip_data_to_plot(available_equips,equip_amount_data,start_date,end_date):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    x_data1 = equip_amount_data.index.get_level_values(0).values\n",
    "    y_data1 = equip_amount_data['Quantidade de Equipamentos'].values.astype(int)\n",
    "    first_record = x_data1[0]\n",
    "    \n",
    "    x_data2 = available_equips.index.values\n",
    "    y_data2 = available_equips['Quantidade Disponível'].values.astype(int)\n",
    "\n",
    "    return(x_data1,y_data1,x_data2,y_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_empty_data(df,start_date,end_date):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    # Checks if dataframe is single index or multiindex\n",
    "    if isinstance(df.index, pd.MultiIndex): \n",
    "        after_start_date = df.index.get_level_values(0) >= start_date\n",
    "        before_end_date = df.index.get_level_values(0) <= end_date\n",
    "        between_two_dates = after_start_date & before_end_date\n",
    "        empty_flag = df[between_two_dates].index.get_level_values(0).empty\n",
    "    else:\n",
    "        after_start_date = df.index >= start_date\n",
    "        before_end_date = df.index <= end_date\n",
    "        between_two_dates = after_start_date & before_end_date\n",
    "        empty_flag = df[between_two_dates].index.empty\n",
    "    return(empty_flag,between_two_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções de aquisição de custo de material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_material_cost_data(material_path_list):\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    material_cost_data_list = []\n",
    "    for file_path in material_path_list:\n",
    "        material_cost_data = pd.read_excel(file_path,skiprows=3,header=2)\n",
    "        material_cost_data['Data Saida'] = pd.to_datetime(material_cost_data['Data Saida'],dayfirst=True)\n",
    "        material_cost_data.sort_values(by=['Data Saida'], inplace=True)  \n",
    "        material_cost_data_list.append(material_cost_data)\n",
    "    material_cost_data = pd.concat(material_cost_data_list,ignore_index=True)\n",
    "    material_cost_data.drop_duplicates(inplace=True)\n",
    "    material_cost_data.set_index(['Data Saida'],inplace=True)\n",
    "    return(material_cost_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_external_cost_data(external_path_list):\n",
    "    import pandas as pd\n",
    "    import os   \n",
    "    external_cost_data_list = []\n",
    "    for file_path in external_path_list:\n",
    "        external_cost_data = pd.read_excel(file_path,skiprows=3,header=2)\n",
    "        external_cost_data['Data Encerramento'] = pd.to_datetime(external_cost_data['Data Encerramento'],dayfirst=True)\n",
    "        external_cost_data.sort_values(by=['Data Encerramento'], inplace=True)  \n",
    "        external_cost_data_list.append(external_cost_data)\n",
    "    external_cost_data = pd.concat(external_cost_data_list,ignore_index=True)\n",
    "    external_cost_data.drop_duplicates(inplace=True)\n",
    "    external_cost_data.set_index(['Data Encerramento'],inplace=True)\n",
    "    return(external_cost_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ipca(ipca_path_list):\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    ipca_list = []\n",
    "    for file_path in ipca_path_list:\n",
    "        ipca = pd.read_excel(file_path,skiprows=3,header=0,skipfooter=1).T\n",
    "        new_header = ipca.iloc[0] #grab the first row for the header\n",
    "        ipca = ipca[1:] #take the data except the header row\n",
    "        ipca.columns = new_header #set the header row as the df header\n",
    "        ipca.dropna(inplace=True)\n",
    "    #     import dateparser\n",
    "    #     ipca.index = ipca.index.map(dateparser.parse)\n",
    "        from datetime import datetime\n",
    "        dict_month_pt = {'janeiro':'1','fevereiro':'2','março':'3','abril':'4','maio':'5','junho':'6','julho':'7','agosto':'8',\n",
    "                            'setembro':'9','outubro':'10','novembro':'11','dezembro':'12'}\n",
    "        new_indexes = []\n",
    "        for c,idx in enumerate(ipca.index):\n",
    "            for mes,number in dict_month_pt.items():\n",
    "                idx = idx.replace(mes, number)\n",
    "            new_indexes.append(datetime.strptime(idx, '%m %Y'))\n",
    "        ipca.index = new_indexes\n",
    "\n",
    "        ipca.reset_index(inplace=True)\n",
    "        ipca = ipca.rename(columns = {'index':'Data'})\n",
    "        ipca_list.append(ipca)\n",
    "    ipca = pd.concat(ipca_list)\n",
    "    ipca.drop_duplicates(inplace=True)\n",
    "    ipca.dropna(inplace=True)\n",
    "    ipca.set_index(['Data'],inplace=True)\n",
    "    ipca = ipca.squeeze()\n",
    "    return(ipca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_equip_monthly_cost(equip,cost_data,ipca):\n",
    "    import dateparser\n",
    "    import pandas as pd\n",
    "    lacking_inflation_corr = True\n",
    "    try:\n",
    "        selected_equip = cost_data['Tipo Equipamento']==equip[0]\n",
    "        for eq in equip:\n",
    "            selected_equip = (selected_equip) | (cost_data['Tipo Equipamento']==eq)\n",
    "    except:\n",
    "        selected_equip = cost_data['Tipo']==equip[0]\n",
    "        for eq in equip:\n",
    "            selected_equip = (selected_equip) | (cost_data['Tipo']==eq)\n",
    "        \n",
    "    cost = cost_data[selected_equip]['Custo']\n",
    "    cost = cost.sort_index()\n",
    "    monthly_cost = cost.groupby(pd.Grouper(freq=\"M\")).sum()  # DataFrameGroupBy (grouped by Month start frequency)\n",
    "    \n",
    "    if (not ipca.empty) & (not monthly_cost.empty):\n",
    "        lacking_inflation_corr = False\n",
    "        diff_days = pd.Timestamp(monthly_cost.index[-1].strftime('%Y-%m')) - pd.Timestamp(ipca.index[-1].strftime('%Y-%m'))\n",
    "\n",
    "        if (diff_days>=pd.Timedelta(28,'D')) & (diff_days<=pd.Timedelta(31,'D')):\n",
    "\n",
    "            ipca = ipca.append(ipca.tail(1))\n",
    "\n",
    "            as_list = ipca.index.tolist()\n",
    "            as_list[-1] = monthly_cost.index[-1]\n",
    "            ipca.index = as_list\n",
    "\n",
    "        for idx in monthly_cost.index.strftime('%B %Y'):\n",
    "            #if ipca contains the corresponding month/year -> correct inflation in that month/year\n",
    "            if ipca.index.strftime('%B %Y').str.contains(idx).any():\n",
    "                monthly_cost[idx] *= ipca[-1]/ipca[ipca.index.strftime('%B %Y').get_loc(idx)]\n",
    "            #otherwise -> do nothing but warn user up to which date inflation was corrected\n",
    "            else:\n",
    "                lacking_inflation_corr = True\n",
    "    return(monthly_cost,lacking_inflation_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrange_cost_data_to_plot(material_monthly_cost,external_monthly_cost,equip_amount_data):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    #Apply masks\n",
    "    x_data1 = equip_amount_data.index.get_level_values(0).values\n",
    "    y_data1 = equip_amount_data['Quantidade de Equipamentos'].values.astype(int)\n",
    "\n",
    "    \n",
    "    x_data2 = material_monthly_cost.index.values\n",
    "    y_data2 = material_monthly_cost.values \n",
    "    \n",
    "    x_data3 = external_monthly_cost.index.values\n",
    "    y_data3 = external_monthly_cost.values\n",
    "\n",
    "    return(x_data1,y_data1,x_data2,y_data2,x_data3,y_data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
